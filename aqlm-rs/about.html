<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <title>AQLM.rs</title>
    <style>
        /** {
            outline: 1px solid red;
        }*/
        * {
            font-family: -apple-system,BlinkMacSystemFont,Inter,ui-sans-serif,system-ui,Segoe UI,Roboto,Ubuntu,Cantarell,Noto Sans,sans-serif,Helvetica Neue,Arial,"Apple Color Emoji","Segoe UI Emoji",Segoe UI Symbol,"Noto Color Emoji";
        }
        a {
            color: black;
        }
        html {
            height: 100%;
        }
        body {
            padding: 0px;
            margin: 0px;
            width: 100%;
            height: 100%;
            display: flex;
            justify-content: start;
            flex-direction: column;
        }
        #main-text {
            padding: 14px;
            /*overflow-x: hidden;*/
            /*overflow-y: auto;*/

            max-width: 810px;

            display: flex;
            justify-content: start;
            flex-direction: column;
        }
        #description > h2 {
            font-size: 26px;
        }
        p {
            /*font-size: 18px;*/
            margin-top: 10px;
            margin-bottom: 10px;
        }
        #main-text > h1 {
            /*font-size: 18px;*/
            /*margin-top: 60px;*/
            /*margin-bottom: 10px;*/
        }
        #main-text > h2 {
            /*font-size: 18px;*/
            margin-top: 30px;
            margin-bottom: 10px;
        }
        #main-text > h3 {
            /*font-size: 18px;*/
            margin-top: 10px;
            margin-bottom: 20px;
        }
        #main-text-wrapper {
            display: flex;
            justify-content: center;
        }
        #video-demo {
            margin-top: 20px;
            max-width: 500px;
            aspect-ratio: 16 / 9;
        }
        #title {
            margin-top: 40px;
            margin-bottom: 10px;
        }
        #how-this-works {
            margin-top: 60px;
            margin-bottom: 10px;
        }
    </style>

    <style>
        #header {
            display: flex;
            padding-left: 20px;
            padding-right: 20px;
            justify-content: space-between;
            flex-direction: row;
            border-bottom: 1px solid #e6e6e6;
        }

        #header a {
            text-decoration: none;
        }

        #header a:hover {
            text-decoration: underline;
        }

        #header-items {
            display: flex;
        }
        .header-items-horizontal {
            flex-direction: row;
        }
        .header-items-vertical {
            flex-direction: column;
        }
        .header-item {
            height: 60px;
            display: flex;
            justify-content: center;
            flex-direction: column;
        }
        .header-not-first-item {
        }
        .header-not-first-item-horizontal {
            margin-left: 30px;
        }

        .header-first-item a {
            font-size: 20px;
            /*font-weight: bold;*/
        }

        .header-item a {
            font-size: 20px;
        }
    </style>

    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.0.0-beta3/css/all.min.css">
</head>
<body>
<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
    (function(m,e,t,r,i,k,a){m[i]=m[i]||function(){(m[i].a=m[i].a||[]).push(arguments)};
        m[i].l=1*new Date();
        for (var j = 0; j < document.scripts.length; j++) {if (document.scripts[j].src === r) { return; }}
        k=e.createElement(t),a=e.getElementsByTagName(t)[0],k.async=1,k.src=r,a.parentNode.insertBefore(k,a)})
    (window, document, "script", "https://mc.yandex.ru/metrika/tag.js", "ym");

    ym(98411300, "init", {
        clickmap:true,
        trackLinks:true,
        accurateTrackBounce:true
    });
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/98411300" style="position:absolute; left:-9999px;" alt="" /></div></noscript>
<!-- /Yandex.Metrika counter -->

<div id="header">
    <div id="header-items" class="header-items-horizontal">
        <div class="header-item header-first-item"><a href="./">AQLM.rs</a></div>
        <div class="header-item header-not-first-item header-not-first-item-horizontal"><a href="./">Demo</a></div>
        <div class="header-item header-not-first-item header-not-first-item-horizontal"><a href="./about.html">About</a></div>
        <div class="header-item header-not-first-item header-not-first-item-horizontal"><a href="https://github.com/galqiwi/demo-aqlm-rs">Source</a></div>
    </div>
<!--    <div class="header-item"><h3><a href="javascript:void(0);" class="icon" onclick="switchDirection()"><i class="fa fa-bars"></i></a></h3></div>-->
</div>

<div id="main-text-wrapper">
<div id="main-text">
    <h1 id="title">Run Llama-3.1-8B directly in a browser</h1>
    <h3 style="margin-bottom: 10px">With state of the art 2 bit compression</h3>
    <p style="margin-top: 10px">Made by <a href="https://galqiwi.github.io">galqiwi</a>.</p>

    <h2 id="how-to-try">How to try</h2>
    <p>Simply visit the <a href="./">demo</a> page of this project.</p>
    <iframe id="video-demo" src="https://www.youtube.com/embed/fPOHT4Zf_NA" title="out" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe>

    <h1 id="how-this-works">How this works</h1>

    <h2 id="tl-dr">TL;DR</h2>
    <p>I implemented multithreaded CPU inference for Llama 3.1-8b with AQLM+PV and LLM.int8() quantization from scratch in Rust. I then deployed it in the browser using WebAssembly and Web Workers.</p>
    <h2 id="how-it-started">How it started</h2>
    <p>In May 2024, my colleagues and I published a paper introducing a new compression method called PV-tuning. This method enhances existing compression techniques by refining compressed models without altering their representations. When combined with AQLM — a method developed in January 2024 — PV-tuning achieves state-of-the-art results in 2-bit compression.</p>
    <p>Around the time we published our paper, Meta released Llama 3.1-8b. I thought it would be fun to run this model in a browser using our method, so I began working on it. Implementing LLM inference in a low-level language like Rust proved to be a fascinating challenge — one I highly recommend. It forces you to understand all the intricate details that you might overlook when using high-level libraries like Transformers.</p>
    <h2 id="the-power-of-rust">The Power of Rust</h2>
    <p>During my bachelor&#39;s degree, I learned Rust at the Yandex School of Data Analysis. I liked the language but hadn&#39;t had a chance to use it in real projects. This project provided an excellent opportunity, as Rust is ideal for compiling to WebAssembly.</p>
    <p>To my pleasant surprise, many fundamental ML technologies I needed were already implemented in Rust. These included Safetensors — a simple format for storing tensors made by Hugging Face — and tiktoken, the BPE tokenizer created by OpenAI that Llama 3.1 uses.</p>
    <h2 id="multithreading-with-web-workers">Multithreading with web workers</h2>
    <p>I implemented multithreading using web workers. These workers allow bidirectional communication through message passing.</p>
    <p>My data-parallel solution splits all matrices by output dimension, with each worker receiving a single slice of each matrix.</p>
    <p>The trickiest part was facilitating communication between workers and the main thread. To achieve this, I developed a custom RPC stack with Rust-JavaScript interoperability.</p>
    <p>When a client needs to multiply a vector by a matrix, it creates a request enum instance, serializes it, and sends it to JavaScript. JavaScript then forwards this to the worker, which deserializes, processes, and re-serializes the result before sending it back. After that Javascript sends it to the client and the client deserializes it.</p>
    <p>This approach boosted performance by approximately 2x on my M1 MacBook Pro.</p>
    <h2 id="quantization-kernels">Quantization kernels</h2>
    <p>I implemented quantization kernels for AQLM and LLM.int8(). While I managed to implement int8 quantization entirely in safe Rust, AQLM required some
        <a href="https://doc.rust-lang.org/book/ch19-01-unsafe-rust.html">unsafe</a> code.</p>
    <p>I also conducted a small study on optimal data layout for AQLM quantization by code-generating different layouts and measuring their performance. It turned out that reordering data in memory can yield about a 10% performance improvement.</p>
    <h2 id="open-source">Open-source</h2>
    <p>I published the source code on GitHub. You can find it <a href="https://github.com/galqiwi/demo-aqlm-rs">here</a>.</p>
    <h2 id="performance">Performance</h2>
    <p>Different computers should have different performance. On my M1 MacBook Pro, the inference speed is 1.4 tokens/s.</p>
    <h2 id="credits">Credits</h2>
    <p>
        AQLM.rs was completed during my work at Yandex Research.
        Special thanks to Daniil Pavlov for helping me with the project.
    </p>
    <p>If you have any questions, feel free to contact me. You can find my contact information <a href="https://galqiwi.github.io/">here</a>.</p>
</div>
</div>
</body>
</html>